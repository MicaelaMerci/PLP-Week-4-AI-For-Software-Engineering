# PLP-Week-4-AI-For-Software-Engineering
# Part 1: Theoretical_Analysis

## 1. Short_Answer_ Questions

### Q1: Explain how AI-driven code generation tools (e.g., GitHub Copilot) reduce development time. What are their limitations?
Answer:AI-driven code generation tools like GitHub Copilot help reduce development time by suggesting relevant code snippets, completing functions, and generating repetitive or boilerplate code automatically. This speeds up the coding process and allows developers to focus on problem-solving and logic rather than manual typing.
How they reduce development time:
- Faster coding: Auto-complete and code suggestions save time on routine tasks.  
- Improved productivity: Reduces the need to search for syntax or examples online.  
- Error reduction: Minimizes typos and syntax errors through intelligent suggest.
- Learning aid: Helps beginners learn coding patterns and best practices in real time.

   Limitations:
- May generate incorrect or insecure code.  
- Developers risk over-reliance on AI assistance.  
- Limited project context understanding, leading to irrelevant suggestions.  
- Potential licensing issues with generated code.  
- Cannot deeply debug or optimize complex logic.


### Q2: Compare supervised and unsupervised learning in the context of automated bug detection.

Answer:
-Supervised learning uses labeled data â€” examples of code that are already marked as buggy or clean. The model learns from these examples to predict whether new code contains bugs. This approach is accurate when large, high-quality labeled datasets are available.

-Unsupervised learning, on the other hand, does not require labeled data. Instead, it looks for patterns or anomalies in the code that deviate from normal behavior, which might indicate potential bugs. It is useful when labeled data is scarce or unavailable.  


### Q3: Why is bias mitigation critical when using AI for user experience personalization?

Answer:
-Bias mitigation is critical in AI-driven user experience personalization because biased algorithms can lead to unfair, inaccurate, or discriminatory outcomes. If an AI model is trained on biased data, it may favor certain groups of users over others, resulting in unequal recommendations, content visibility, or access to features.

-By applying bias mitigation techniques, developers ensure that personalization remains fair, inclusive, and representative of all user groups. This helps build trust, improve user satisfaction, and protect against ethical and legal issues related to discrimination or unfair treatment.
